# Dataset Validator con Interpretaci√≥n mediante IA Local

## Descripci√≥n general

Este proyecto presenta un ejemplo completo y accesible de un flujo de trabajo para la validaci√≥n inicial de datasets, incorporando interpretaci√≥n autom√°tica de resultados mediante un modelo de lenguaje ejecutado en entorno local.

El objetivo no es automatizar el an√°lisis de datos ni reemplazar decisiones humanas, sino mostrar c√≥mo estructurar un proceso claro, reproducible y responsable en etapas tempranas de un proyecto de an√°lisis.

---

## Problema que aborda

En la pr√°ctica profesional, la validaci√≥n inicial de datos suele realizarse de manera informal o impl√≠cita.  
Este proyecto propone una alternativa estructurada que permite:

- detectar problemas b√°sicos de calidad de datos
- documentar decisiones
- separar reglas autom√°ticas de interpretaci√≥n humana
- generar evidencia reutilizable

---

## Alcance del sistema

El sistema realiza las siguientes tareas:

1. Analiza un dataset en formato CSV
2. Eval√∫a valores nulos en columnas categ√≥ricas
3. Aplica un umbral configurable
4. Toma una decisi√≥n autom√°tica:
   - **APTO**
   - **REVISAR**
5. Genera un reporte estructurado en formato JSON
6. Utiliza un modelo de lenguaje local para interpretar el reporte
7. Guarda la interpretaci√≥n en un archivo de texto

![Vista de la aplicaci√≥n](img/captura.png)
---

## Qu√© NO hace este proyecto

- No limpia datos
- No modifica el dataset original
- No entrena modelos de machine learning
- No utiliza servicios en la nube
- No env√≠a datos a plataformas externas

El foco est√° en **proceso, criterio y buenas pr√°cticas**, no en automatizaci√≥n total.

---

## Uso responsable de IA

La IA utilizada en este proyecto:

- se ejecuta completamente en entorno local
- no tiene acceso al dataset original
- recibe √∫nicamente un reporte resumido
- no toma decisiones finales
- no realiza c√°lculos

Su rol es **interpretar resultados**, no analizar datos crudos.

---

## Seguridad y privacidad

Todo el flujo de trabajo se ejecuta localmente en la computadora del usuario:

- los datos no salen del entorno local
- no se utilizan APIs externas
- no se requiere conexi√≥n a internet
- no se sube informaci√≥n a servicios de terceros

Este enfoque es adecuado para trabajar con datos sensibles o confidenciales.

---

## Estructura del proyecto
```
dataset_validator/
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ ‚îî‚îÄ‚îÄ adult.csv
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ ‚îú‚îÄ‚îÄ inspect_data.py
‚îÇ ‚îî‚îÄ‚îÄ interpretar_reporte.py
‚îÇ
‚îú‚îÄ‚îÄ reporte_validacion.json
‚îú‚îÄ‚îÄ interpretacion_reporte.txt
‚îî‚îÄ‚îÄ README.md
```

---

## Requisitos

- Python 3.10 o superior
- Pandas
- Requests
- LM Studio con un modelo local compatible (por ejemplo Nous Hermes Mistral)

No se requieren cuentas, pagos ni servicios externos.

---

## Qu√© se espera aprender con este proyecto

Al finalizar este ejercicio, el estudiante deber√≠a ser capaz de:

- comprender la importancia de la validaci√≥n inicial de datos
- aplicar reglas autom√°ticas simples con criterio
- separar l√≥gica de interpretaci√≥n
- integrar IA de manera justificada y controlada
- pensar en t√©rminos de procesos reutilizables

---

## P√∫blico objetivo

Este proyecto est√° pensado para estudiantes de an√°lisis de datos con nivel intermedio que deseen dar el primer paso hacia flujos de trabajo m√°s estructurados sin introducir complejidad innecesaria.

---

## üîß Requerimientos de hardware

Para ejecutar el flujo completo de este repositorio (an√°lisis de datos con Python y generaci√≥n de reportes con IA local):  

- **Python + scripts:** la parte de Python es liviana y funciona en cualquier m√°quina con Python 3.x y memoria est√°ndar.  
- **IA local (LM Studio + modelo `nous‚Äëhermes‚Äë2‚Äëmistral‚Äë7b‚Äëdpo`):** se beneficia de hardware m√°s potente para un rendimiento √≥ptimo:  
  - **GPU:** ‚â•12‚ÄØGB de VRAM para inferencia eficiente.  
  - **RAM del sistema:** 16‚ÄØ‚Äì‚ÄØ32‚ÄØGB.  
  - **Almacenamiento:** SSD con espacio suficiente para modelos y datasets.  
- **Opcional:** puede ejecutarse sin GPU (solo CPU), aunque con menor velocidad.  

üí° Se recomienda usar siempre un **entorno virtual (`venv`)** para aislar dependencias y mantener el entorno seguro.

---

## Dataset

El dataset utilizado en este proyecto es **Adult Income Dataset**, disponible p√∫blicamente en Kaggle:

https://www.kaggle.com/datasets/wenruliu/adult-income-dataset

### Descripci√≥n

Este conjunto de datos contiene informaci√≥n demogr√°fica y laboral de personas adultas.

Incluye variables como:
- Edad
- Nivel educativo
- Estado civil
- Tipo de trabajo
- Ocupaci√≥n
- Horas trabajadas por semana
- Pa√≠s de origen
- Ingreso (variable objetivo)

El dataset es ampliamente utilizado con fines educativos para pr√°cticas de:
- An√°lisis exploratorio de datos (EDA)
- Limpieza y validaci√≥n de datos
- Preparaci√≥n de datasets para modelos de machine learning
- Discusi√≥n sobre sesgos y calidad de datos

### Licencia y uso

El dataset es de acceso p√∫blico y se utiliza en este proyecto **exclusivamente con fines educativos**.
No contiene informaci√≥n personal identificable y no se incorporan datos sensibles adicionales durante el procesamiento.



